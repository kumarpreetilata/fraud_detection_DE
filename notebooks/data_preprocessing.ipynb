{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing for Real-Time Fraud Detection\n",
    "\n",
    "This notebook focuses on the data processing tasks necessary to clean and prepare the dataset for analysis and modeling. It includes steps for handling missing values, encoding categorical variables, and creating new features.\n",
    "\n",
    "## 1. Import Libraries\n",
    "\n",
    "First, we need to import the necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Data\n",
    "\n",
    "Load the dataset that we will process. This can be from local storage or Azure Blob Storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load data from Azure Blob Storage or local path\n",
    "data_path = 'path_to_your_data_file.csv'  # Update with your file path\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Overview\n",
    "\n",
    "Check the shape of the dataset and get basic statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check the shape of the dataset\n",
    "print(\"Shape of the dataset:\", data.shape)\n",
    "\n",
    "# Get basic statistics\n",
    "data.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check for Missing Values\n",
    "\n",
    "Identify and handle missing values in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "missing_values[missing_values > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# Example: Impute numerical features with the mean and categorical features with the mode\n",
    "numerical_features = ['amount', 'account_age_days', 'previous_fraud_count']\n",
    "categorical_features = ['location', 'is_international']\n",
    "\n",
    "imputer_num = SimpleImputer(strategy='mean')\n",
    "data[numerical_features] = imputer_num.fit_transform(data[numerical_features])\n",
    "\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "data[categorical_features] = imputer_cat.fit_transform(data[categorical_features])\n",
    "\n",
    "print(\"Missing values handled.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encoding Categorical Variables\n",
    "\n",
    "Encode categorical variables using One-Hot Encoding to prepare for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding for categorical variables\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Display the first few rows of the processed data\n",
    "data_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering\n",
    "\n",
    "Create any additional features that may enhance the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example: Creating a feature that indicates whether a transaction amount is above a certain threshold\n",
    "threshold = 1000  # Define a threshold for high-value transactions\n",
    "data_encoded['high_value_transaction'] = np.where(data_encoded['amount'] > threshold, 1, 0)\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "data_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Processed Data\n",
    "\n",
    "Save the processed dataset to a new CSV file or to Azure Blob Storage for further use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save processed data to a CSV file\n",
    "processed_data_path = 'processed_fraud_detection_data.csv'  # Update with your desired file path\n",
    "data_encoded.to_csv(processed_data_path, index=False)\n",
    "\n",
    "print(\"Processed data saved to:\", processed_data_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
